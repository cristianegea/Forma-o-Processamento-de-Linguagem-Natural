{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f21102e-74dd-4797-b4fc-984348937d11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /databricks/python3/lib/python3.10/site-packages (4.30.2)\r\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.16.4)\r\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (6.0)\r\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from transformers) (3.6.0)\r\nRequirement already satisfied: safetensors>=0.3.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.3.2)\r\nRequirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.10/site-packages (from transformers) (2022.7.9)\r\nRequirement already satisfied: requests in /databricks/python3/lib/python3.10/site-packages (from transformers) (2.28.1)\r\nRequirement already satisfied: numpy>=1.17 in /databricks/python3/lib/python3.10/site-packages (from transformers) (1.21.5)\r\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.13.3)\r\nRequirement already satisfied: tqdm>=4.27 in /databricks/python3/lib/python3.10/site-packages (from transformers) (4.64.1)\r\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from transformers) (21.3)\r\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.3.0)\r\nRequirement already satisfied: fsspec in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.7.1)\r\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\r\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\r\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (1.26.11)\r\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (3.3)\r\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (2022.9.14)\r\n\r\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.2.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3\u001B[0m\r\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d69f80e6-b8ea-475f-bdfb-e527b3d299c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Biblioteca \n",
    "import transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dd130dd-845a-4900-812c-04b957e1c686",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ddde8335fa41e096e15dc4a8b3e092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/647 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c7ae084c574672b000c62680658c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cae33680f124ea8a1425b5615f8df94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d20ebe3e50423692584ffd15d54d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/210k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23e22d5521341628728bf6f591d757d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a09cc053f54f73a93e95c5299062e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Criação do método pipeline - nesse caso são especificados a tarefa desejada e o modelo a ser utilizado\n",
    "mascarar = pipeline(\"fill-mask\", model=\"neuralmind/bert-base-portuguese-cased\")\n",
    "# se não for especificado o modelo, será utilizado o modelo padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5720c4e-6907-4964-b533-804dbac586e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.5944014191627502, 'token': 8105, 'token_str': 'chão', 'sequence': 'Existe uma chance do copo cair no chão'}\n{'score': 0.045443546026945114, 'token': 2187, 'token_str': 'rio', 'sequence': 'Existe uma chance do copo cair no rio'}\n{'score': 0.04219302535057068, 'token': 528, 'token_str': 'mar', 'sequence': 'Existe uma chance do copo cair no mar'}\n{'score': 0.03341998532414436, 'token': 4848, 'token_str': 'fogo', 'sequence': 'Existe uma chance do copo cair no fogo'}\n{'score': 0.022562772035598755, 'token': 14575, 'token_str': 'lixo', 'sequence': 'Existe uma chance do copo cair no lixo'}\n"
     ]
    }
   ],
   "source": [
    "texto = mascarar(\"Existe uma chance do copo cair no [MASK]\")\n",
    "for x in range(len(texto)):\n",
    "  print(texto[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bd973fc-6923-4559-a4ff-1f71b4541397",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.5944014191627502, 'token': 8105, 'token_str': 'chão', 'sequence': 'Existe uma chance do copo cair no chão'}, {'score': 0.045443546026945114, 'token': 2187, 'token_str': 'rio', 'sequence': 'Existe uma chance do copo cair no rio'}, {'score': 0.04219302535057068, 'token': 528, 'token_str': 'mar', 'sequence': 'Existe uma chance do copo cair no mar'}, {'score': 0.03341998532414436, 'token': 4848, 'token_str': 'fogo', 'sequence': 'Existe uma chance do copo cair no fogo'}, {'score': 0.022562772035598755, 'token': 14575, 'token_str': 'lixo', 'sequence': 'Existe uma chance do copo cair no lixo'}]\n[{'score': 0.5167432427406311, 'token': 771, 'token_str': 'Brasil', 'sequence': 'Brasília é a capital do Brasil'}, {'score': 0.1981545239686966, 'token': 806, 'token_str': 'país', 'sequence': 'Brasília é a capital do país'}, {'score': 0.03764709457755089, 'token': 4953, 'token_str': 'País', 'sequence': 'Brasília é a capital do País'}, {'score': 0.024318614974617958, 'token': 1147, 'token_str': 'mundo', 'sequence': 'Brasília é a capital do mundo'}, {'score': 0.015301560051739216, 'token': 2200, 'token_str': 'futebol', 'sequence': 'Brasília é a capital do futebol'}]\n"
     ]
    }
   ],
   "source": [
    "texto = mascarar([\"Existe uma chance do copo cair no [MASK]\",\"Brasília é a capital do [MASK]\"])\n",
    "for x in range(len(texto)):\n",
    "  print(texto[x])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Preenchimento de Lacunas usando Hugging Face",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
